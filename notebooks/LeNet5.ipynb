{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2IufuH49fgO"
   },
   "source": [
    "# Clasificación de imágenes\n",
    "\n",
    "En este cuaderno exploraremos una tarea de clasificación de imágenes. En particular trataremos de entrenar una red neuronal convolucional, la vieja y famosa [LeNet5](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) en el dataset [MNIST](http://yann.lecun.com/exdb/mnist/), el cual consiste en imágenes de los dígitos del 0 al 9 escritos por personas.\n",
    "\n",
    "Para la implementación usaremos [Keras](https://keras.io/) que puede ser visto como un API de alto nivel sobre TensorFlow. En particular usaremos la [API de modelo sequencial](https://keras.io/models/sequential/) y las capas convolucionales y de pooling predefinidas por ellos en el módulo [layers](https://keras.io/layers/about-keras-layers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8pLMB4o9DLH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btzfl3TE_Isk"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3S7FEp53A6RC"
   },
   "source": [
    "primero observemos los datos que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1538937655994,
     "user": {
      "displayName": "Sebastian Rodriguez Colina",
      "photoUrl": "",
      "userId": "15883086893181703875"
     },
     "user_tz": 300
    },
    "id": "KsvFTSmX_IpO",
    "outputId": "6a8ce4b7-fb5a-4e5f-e50b-1e45fae346fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train is (60000, 28, 28)\n",
      "Shape of y_train is (60000,)\n",
      "Shape of X_test is (10000, 28, 28)\n",
      "Shape of y_test is (10000,)\n"
     ]
    }
   ],
   "source": [
    "msg = \"Shape of {} is {}\"\n",
    "print(msg.format('X_train', X_train.shape))\n",
    "print(msg.format('y_train', y_train.shape))\n",
    "print(msg.format('X_test', X_test.shape))\n",
    "print(msg.format('y_test', y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SalWRIw4gQdp"
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOU7lyWi0J2_"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAEgGuMRBTuM"
   },
   "source": [
    "tenemos 60mil imágenes de entrenamiento y 10mil de prueba, cada imagen tiene 28 pixeles de ancho y alto. Miremos unas cuantas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyyEYQaE_InF"
   },
   "outputs": [],
   "source": [
    "def sample_data(data, sample_size=5):\n",
    "    indices = np.random.randint(0, data.shape[0], size=sample_size)\n",
    "    return data[indices, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVHoQZy0EIzd"
   },
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    cols = 5\n",
    "    rows = int(images.shape[0]/cols)\n",
    "    \n",
    "    fig = plt.figure(figsize=(rows*5, cols*5))\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        ax=fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1538937659607,
     "user": {
      "displayName": "Sebastian Rodriguez Colina",
      "photoUrl": "",
      "userId": "15883086893181703875"
     },
     "user_tz": 300
    },
    "id": "l4J69jba_IkU",
    "outputId": "521c4939-1df5-439f-9a46-d34f4e18f4a2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x1800 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_images = sample_data(X_train)\n",
    "show_images(sample_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cQDaspPvgsQ"
   },
   "source": [
    "La implementación de Keras nos exige que nuestro conjunto de imágenes sea de la forma [-1, height, width, n_ch], por lo que debemos cambiar el formato que tenemos; además, como el máximo valor en las imágenes es 255, podemos escalar muy fácilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJrm3BYsvyqH"
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train.astype(np.float32), (-1, IMG_HEIGHT, IMG_WIDTH, 1))/255\n",
    "X_test = np.reshape(X_test.astype(np.float32), (-1, IMG_HEIGHT, IMG_WIDTH, 1))/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRkUkoNL-CKa"
   },
   "source": [
    "keras también nos exige que nuestros labels estén en formato one-hot encodding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsRZbhwt0Haw"
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vU09UYRJ-KYv"
   },
   "source": [
    "A continuación definimos nuestro modelo, como una serie de pasos que llevan de la imagen de entrada a las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tzU07fJhOlk"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=6, kernel_size=(5,5), activation='tanh',\n",
    "        padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    )\n",
    ")\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(16, (5,5), activation='tanh'))\n",
    "model.add(tf.keras.layers.AveragePooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(120, (5,5), activation='tanh'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(84, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53BdV6JF-V1L"
   },
   "source": [
    "ahora si, podemos entrenar nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 445609,
     "status": "ok",
     "timestamp": 1538938731171,
     "user": {
      "displayName": "Sebastian Rodriguez Colina",
      "photoUrl": "",
      "userId": "15883086893181703875"
     },
     "user_tz": 300
    },
    "id": "BisHUx_02vr9",
    "outputId": "7f29070d-90d9-47a8-ae5a-1e524468397f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 41s 677us/step - loss: 0.1580 - acc: 0.9535 - val_loss: 0.1285 - val_acc: 0.9613\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 40s 662us/step - loss: 0.1010 - acc: 0.9702 - val_loss: 0.1089 - val_acc: 0.9669\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 39s 653us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0983 - val_acc: 0.9716\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 39s 652us/step - loss: 0.0633 - acc: 0.9817 - val_loss: 0.0927 - val_acc: 0.9722\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 43s 716us/step - loss: 0.0539 - acc: 0.9843 - val_loss: 0.0907 - val_acc: 0.9729\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 40s 668us/step - loss: 0.0470 - acc: 0.9863 - val_loss: 0.0864 - val_acc: 0.9741\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 44s 733us/step - loss: 0.0421 - acc: 0.9877 - val_loss: 0.0878 - val_acc: 0.9744\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 43s 724us/step - loss: 0.0391 - acc: 0.9883 - val_loss: 0.0830 - val_acc: 0.9760\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 42s 703us/step - loss: 0.0379 - acc: 0.9876 - val_loss: 0.0963 - val_acc: 0.9744\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 40s 673us/step - loss: 0.0413 - acc: 0.9872 - val_loss: 0.0849 - val_acc: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a954f60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, epochs=10, batch_size=320,\n",
    "    verbose=1, validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVjhYiu57goz"
   },
   "outputs": [],
   "source": [
    "y_train_probs = model.predict(X_train)\n",
    "y_test_probs = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UFIzCYJ87td"
   },
   "outputs": [],
   "source": [
    "y_train_preds = np.argmax(y_train_probs, axis=1)\n",
    "y_test_preds = np.argmax(y_test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzdhixvR7lhO"
   },
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1538939744639,
     "user": {
      "displayName": "Sebastian Rodriguez Colina",
      "photoUrl": "",
      "userId": "15883086893181703875"
     },
     "user_tz": 300
    },
    "id": "0FNVXczRIJPD",
    "outputId": "e600fcaa-7da4-4bbd-97d0-d03e1b0b5c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Report on train data-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5923\n",
      "           1       0.99      1.00      1.00      6742\n",
      "           2       0.99      0.99      0.99      5958\n",
      "           3       0.99      0.99      0.99      6131\n",
      "           4       0.99      0.99      0.99      5842\n",
      "           5       0.99      0.99      0.99      5421\n",
      "           6       1.00      0.99      0.99      5918\n",
      "           7       0.99      0.99      0.99      6265\n",
      "           8       0.99      0.99      0.99      5851\n",
      "           9       0.98      0.99      0.98      5949\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "-------Report on test data-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.96      0.98      0.97      1010\n",
      "           4       0.98      0.97      0.97       982\n",
      "           5       0.98      0.97      0.97       892\n",
      "           6       0.98      0.97      0.98       958\n",
      "           7       0.97      0.98      0.97      1028\n",
      "           8       0.97      0.98      0.97       974\n",
      "           9       0.97      0.96      0.97      1009\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-------Report on train data-----------\")\n",
    "print(classification_report(y_train, y_train_preds))\n",
    "print(\"-------Report on test data-----------\")\n",
    "print(classification_report(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2BMrZNXqLDI_"
   },
   "source": [
    "Espero que veas como una red convolucional puede ser superior a las aproximaciones tradiconales para clasificar imágenes. \n",
    "\n",
    "**Ejercicio:** intenta cambiar hiperparámetros, qué es lo mejor que puedes lograr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIP353SoK6WR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LeNet5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
